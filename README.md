### What is this?
Given are a series of images that explain the Attention mechanism that is part of transformer models. This is not perfect (that's why its in a repo). I'd love feed back on this, additions to this are welcome as well.

If you are interested you can raise a request and I'll upload the blender files here too.

### Images

- 1
![](images/image-1.png)

- 2
![](images/image-2.png)

- 3
![](images/image-3.png)

- 4
![](images/image-4.png)

- 5
![](images/image-5.png)

- 6
![](images/image-6.png)

- 7
![](images/image-7.png)

- 8
![](images/image-8.png)

- 9
![](images/image-9.png)

- 10
![](images/image-10.png)
