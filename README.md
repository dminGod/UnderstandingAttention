### What is this?
Given are a series of images that explain the Attention mechanism that is part of transformer models. This is not perfect (that's why its in a repo). I'd love feed back on this, additions to this are welcome as well.

If you are interested you can raise a request and I'll upload the blender files here too.

### Images

- 1
![](images/image1.png)

- 2
![](images/image2.png)

- 3
![](images/image3.png)

- 4
![](images/image4.png)

- 5
![](images/image5.png)

- 6
![](images/image6.png)

- 7
![](images/image7.png)

- 8
![](images/image8.png)

- 9
![](images/image9.png)

- 10
![](images/image10.png)